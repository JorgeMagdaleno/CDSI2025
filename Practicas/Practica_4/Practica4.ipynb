{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd6a7a6-721d-48de-8463-ace525cf82b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --upgrade scikit-learn fastdtw scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "123498b1-a167-4987-867b-a63639a6a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0821016-6531-4089-bc87-3e12320ab43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para cargar los datos\n",
    "def load_bpm_series(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    bpm_values = []\n",
    "    for line in lines:\n",
    "        try:\n",
    "            bpm = float(line.strip())\n",
    "            bpm_values.append(bpm)\n",
    "        except:\n",
    "            continue\n",
    "    return np.array(bpm_values)\n",
    "\n",
    "\n",
    "\n",
    "# Cargar datos\n",
    "txt_files = glob.glob(os.path.join(\"Datos\", \"*.txt\"))\n",
    "subject_series = {}  \n",
    "\n",
    "for file_path in txt_files:\n",
    "    subject = os.path.splitext(os.path.basename(file_path))[0].lower()\n",
    "    series = load_bpm_series(file_path)\n",
    "    subject_series[subject] = series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dbe3d71-d405-4cd4-9dd5-83e5ec897ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mmss_to_seconds(time_str):\n",
    "    minutes, seconds = time_str.split(\":\")\n",
    "    return int(minutes) * 60 + int(seconds)\n",
    "\n",
    "obs_df = pd.read_csv(\"Datos/Heart_Rate_VR_Data.csv\")\n",
    "obs_df[\"subject\"] = obs_df[\"subject\"].str.lower()\n",
    "\n",
    "obs_df[\"time\"] = obs_df[\"time\"].apply(convert_mmss_to_seconds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16445a58-e309-4f34-9b8e-fff7b40524ba",
   "metadata": {},
   "source": [
    "Aqui segmento los datos con un empalmamiento de 50% entre ellos  para evitar que la parte que causa el miedo se encuentre por el final y no se capture completa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80cd6c20-775b-4653-9879-fa151b65cc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[611. 611. 593. ... 618. 583. 606.]\n",
      " [665. 688. 618. ... 559. 657. 663.]\n",
      " [614. 572. 559. ... 552. 580. 621.]\n",
      " ...\n",
      " [767. 746. 747. ... 993. 987. 973.]\n",
      " [959. 980. 993. ... 922. 910. 926.]\n",
      " [929. 911. 922. ... 818. 868. 820.]]\n",
      "[0 0 0 ... 0 0 0]\n",
      "Número de muestras segmentadas: (1336, 10) (1336,)\n"
     ]
    }
   ],
   "source": [
    "def segment_series(series, window_size, step_size):\n",
    "    segments = []\n",
    "    for start in range(0, len(series) - window_size + 1, step_size):\n",
    "        segments.append(series[start:start+window_size])\n",
    "    return np.array(segments)\n",
    "    \n",
    "# Analizar ventanas de 10 segundos\n",
    "window_size = 10   \n",
    "# Avanzamos de 5 en 5 segundos\n",
    "step_size = 5      \n",
    "\n",
    "dataset_segments = []\n",
    "dataset_labels = []\n",
    "\n",
    "for subject, series in subject_series.items():\n",
    "    segments = segment_series(series, window_size, step_size)\n",
    "    times = np.arange(len(series))\n",
    "    \n",
    "    # TOmar la informacion por sujeto\n",
    "    subj_obs = obs_df[obs_df[\"subject\"] == subject]\n",
    "    \n",
    "    # Cada segmento determinar la el tiempo y asignar el miedo\n",
    "    for seg_idx, seg in enumerate(segments):\n",
    "        start_time = seg_idx * step_size  # aproximación\n",
    "        center_time = start_time + window_size // 2\n",
    "        \n",
    "        # Buscar el evento mas cercano al tiempo:\n",
    "        if not subj_obs.empty:\n",
    "            subj_obs = subj_obs.copy()\n",
    "            subj_obs.loc[:, \"diff\"] = np.abs(subj_obs[\"time\"] - center_time)\n",
    "            closest_event = subj_obs.loc[subj_obs[\"diff\"].idxmin()]\n",
    "            label = closest_event[\"fear level\"]\n",
    "        else:\n",
    "            # si no funciona mejor saltarselo\n",
    "            continue\n",
    "        \n",
    "        dataset_segments.append(seg)\n",
    "        dataset_labels.append(label)\n",
    "\n",
    "# Convertir a arrays\n",
    "X_segments = np.array(dataset_segments)\n",
    "y_segments = np.array(dataset_labels)\n",
    "\n",
    "print(X_segments)\n",
    "print(y_segments)\n",
    "\n",
    "print(\"Número de muestras segmentadas:\", X_segments.shape, y_segments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "471d9e6c-8348-424a-941b-d94c7786c88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Definir la función de distancia DTW\n",
    "def dtw_distance(x, y):\n",
    "    # Aplanar los arrays porque si no no funciona\n",
    "    x = np.asarray(x).ravel()\n",
    "    y = np.asarray(y).ravel()\n",
    "    \n",
    "    # Verificar que x e y sean arrays 1-D\n",
    "    if x.ndim != 1 or y.ndim != 1:\n",
    "        raise ValueError(f\"Forma de x: {x.shape}, Forma de y: {y.shape}\")\n",
    "    \n",
    "    # Implementación personalizada de la distancia euclidiana\n",
    "    def custom_euclidean(u, v):\n",
    "        u = np.asarray(u).ravel()\n",
    "        v = np.asarray(v).ravel()\n",
    "        return np.linalg.norm(u - v)\n",
    "    \n",
    "    # Calcular la distancia DTW\n",
    "    distance, _ = fastdtw(x, y, dist=custom_euclidean)\n",
    "    \n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "750c263b-4772-4fff-aed1-bffad2160afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy con DTW kNN: 0.6408977556109726\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.80       281\n",
      "           1       0.07      0.06      0.06        18\n",
      "           2       0.25      0.10      0.15        29\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.17      0.05      0.08        37\n",
      "           5       0.30      0.44      0.35        25\n",
      "\n",
      "    accuracy                           0.64       401\n",
      "   macro avg       0.26      0.25      0.24       401\n",
      "weighted avg       0.58      0.64      0.60       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3, metric=dtw_distance)\n",
    "\n",
    "# Dividir en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_segments, y_segments, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train = np.array([seg.ravel() for seg in X_train])\n",
    "X_test = np.array([seg.ravel() for seg in X_test])\n",
    "\n",
    "# Entrenar el modelo\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predecir\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Accuracy con DTW kNN:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98561733-fb81-42ee-be83-e0592aee47ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy con DTW kNN y PCA: 0.6408977556109726\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.79       281\n",
      "           1       0.06      0.06      0.06        18\n",
      "           2       0.18      0.07      0.10        29\n",
      "           3       0.00      0.00      0.00        11\n",
      "           4       0.22      0.05      0.09        37\n",
      "           5       0.32      0.28      0.30        25\n",
      "\n",
      "    accuracy                           0.64       401\n",
      "   macro avg       0.25      0.22      0.22       401\n",
      "weighted avg       0.57      0.64      0.59       401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Escalado de variables\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Aplicar PCA\n",
    "pca = PCA(n_components=0.95)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "#Entrenamiento\n",
    "knn.fit(X_train_pca, y_train)\n",
    "\n",
    "# Predecir con una barra de progreso\n",
    "y_pred = knn.predict(X_test_pca)\n",
    "# Evaluar el modelo\n",
    "print(\"Accuracy con DTW kNN y PCA:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d899d3b-9e17-4b45-9c5e-b844c8cf1740",
   "metadata": {},
   "source": [
    "Finalmente mis dos modelos aun si intento escalar los datos parece no hacer nada, presumiblemente porque solamente estoy tomando una serie de datos y no multiples atributos. Otros intentos que hice fue utilizar otros modelos y utilizar los datos que la aplicacion de kubios genera pero los modelos con esos datos parecen ir peorprobablemente debido a que no logre acomodar bien los datos con las observaciones del miedo y los otros datos. Otros modelos que intente tuvieron accuracy de 0.33 y 0.51, esos utilizaren Randomforest y un intento de dtw pero no logre hacer que funcionara como esperaba. Finalmente este modelo con DTW parece ser el mejor con 0.64."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
