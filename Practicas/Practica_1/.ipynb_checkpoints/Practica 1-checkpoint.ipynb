{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "720bcbca-09f1-4e9a-a113-292cb0391981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wave\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890a15f3-73dc-41a6-9f71-2e691c287f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_silent_wav(filepath, duration_sec=1, sample_rate=44100, channels=1, noise_std=5):\n",
    "    \"\"\"\n",
    "    Generates a WAV file that simulates realistic \"silence\" by adding a very low-level noise floor.\n",
    "    This mimics the slight background noise from an open mic when no one is speaking.\n",
    "    \n",
    "    Parameters:\n",
    "        filepath (str): The full path where the WAV file will be saved.\n",
    "        duration_sec (float): Duration of the audio in seconds.\n",
    "        sample_rate (int): Sampling rate.\n",
    "        channels (int): Number of channels.\n",
    "        noise_std (int): Standard deviation (in integer amplitude units) of the noise.\n",
    "                         Adjust this value to simulate more or less background noise.\n",
    "    \"\"\"\n",
    "    n_samples = int(sample_rate * duration_sec)\n",
    "    \n",
    "    # Generate a noise floor: Gaussian noise centered at 0 with a small standard deviation.\n",
    "    # This simulates the \"ambient\" electronic noise of a microphone.\n",
    "    silence = np.random.normal(loc=0, scale=noise_std, size=n_samples * channels)\n",
    "    silence = silence.astype(np.int16)\n",
    "    \n",
    "    with wave.open(filepath, 'w') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(2)  # 16-bit audio: 2 bytes per sample\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(silence.tobytes())\n",
    "\n",
    "def generate_null_audios(n_files=3, duration=1.0):\n",
    "    \"\"\"\n",
    "    Generates a number of silent audio files in Audios/Audios_Null.\n",
    "    \n",
    "    Parameters:\n",
    "        n_files (int): Number of null audio files to create.\n",
    "        duration (float): Duration in seconds for each audio.\n",
    "    \"\"\"\n",
    "    base_folder = \"Audios\"\n",
    "    null_folder = os.path.join(base_folder, \"Audios_Null\")\n",
    "    os.makedirs(null_folder, exist_ok=True)\n",
    "    \n",
    "    for i in range(n_files):\n",
    "        for n in range(5):\n",
    "            file_name = f\"null-0{i+1}_0{n+1}.wav\"\n",
    "            file_path = os.path.join(null_folder, file_name)\n",
    "            generate_silent_wav(file_path, duration_sec=duration)\n",
    "            print(f\"Generated: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bac49017-969c-4f37-9837-bdfb0adeca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audios_into_dataframe(root_folder=\"Audios\", valid_extensions=('.wav', '.mp3', '.m4a', '.flac', '.ogg', '.wma', '.aac')):\n",
    "    \"\"\"\n",
    "    Recursively loads all audio files from the given root folder into a DataFrame.\n",
    "    \n",
    "    Each row includes:\n",
    "      - filepath: Full path to the file.\n",
    "      - filename: File name.\n",
    "      - label: Name of the immediate parent folder.\n",
    "      - audio: Audio data as a numpy array.\n",
    "      - sample_rate: Sampling rate of the loaded audio.\n",
    "      - duration: Duration of the audio in seconds.\n",
    "    \"\"\"\n",
    "    audio_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith(valid_extensions):\n",
    "                full_path = os.path.join(dirpath, filename)\n",
    "                audio_files.append(full_path)\n",
    "    \n",
    "    data = []\n",
    "    for filepath in audio_files:\n",
    "        filename = os.path.basename(filepath)\n",
    "        label = os.path.basename(os.path.dirname(filepath))\n",
    "        try:\n",
    "            audio_data, sample_rate = librosa.load(filepath, sr=None)\n",
    "            duration = librosa.get_duration(y=audio_data, sr=sample_rate)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filepath}: {e}\")\n",
    "            audio_data, sample_rate, duration = None, None, None\n",
    "        \n",
    "        data.append({\n",
    "            'filepath': filepath,\n",
    "            'filename': filename,\n",
    "            'label': label,\n",
    "            'audio': audio_data,\n",
    "            'sample_rate': sample_rate,\n",
    "            'duration': duration\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4544a01-afdc-4ba8-974e-0d970282d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(audio, noise_factor=0.005):\n",
    "    \"\"\"Adds white noise to the audio.\"\"\"\n",
    "    noise = np.random.randn(len(audio))\n",
    "    return audio + noise_factor * noise\n",
    "\n",
    "def apply_time_stretch(audio, rate=1.2):\n",
    "    \"\"\"\n",
    "    Stretches (or compresses) the audio in time.\n",
    "    A rate > 1.0 speeds up the audio; rate < 1.0 slows it down.\n",
    "    \"\"\"\n",
    "    return librosa.effects.time_stretch(audio, rate=rate)\n",
    "\n",
    "def apply_pitch_shift(audio, sr, n_steps=2):\n",
    "    \"\"\"\n",
    "    Shifts the pitch of the audio by n_steps semitones.\n",
    "    \"\"\"\n",
    "    return librosa.effects.pitch_shift(audio, sr=sr, n_steps=n_steps)\n",
    "\n",
    "def change_volume(audio, factor=1.5):\n",
    "    \"\"\"Changes the volume by multiplying the audio signal.\"\"\"\n",
    "    return audio * factor\n",
    "\n",
    "def augment_audio(audio, sr):\n",
    "    \"\"\"\n",
    "    Applies a set of augmentations to an audio sample.\n",
    "    \n",
    "    Returns:\n",
    "        List of tuples: Each tuple contains (augmentation_method, augmented_audio).\n",
    "    \"\"\"\n",
    "    augmentations = []\n",
    "    \n",
    "    # Original (no augmentation)\n",
    "    augmentations.append(('original', audio))\n",
    "    \n",
    "    # Add Noise\n",
    "    noise_audio = add_noise(audio, noise_factor=0.005)\n",
    "    augmentations.append(('noise', noise_audio))\n",
    "    \n",
    "    # Time Stretch (speed up)\n",
    "    try:\n",
    "        ts_audio = apply_time_stretch(audio, rate=1.2)\n",
    "        augmentations.append(('time_stretch', ts_audio))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in time stretching: {e}\")\n",
    "    \n",
    "    # Pitch Shift (raise pitch)\n",
    "    try:\n",
    "        ps_audio = apply_pitch_shift(audio, sr, n_steps=2)\n",
    "        augmentations.append(('pitch_shift', ps_audio))\n",
    "    except Exception as e:\n",
    "        print(f\"Error in pitch shifting: {e}\")\n",
    "    \n",
    "    # Volume Change (increase volume)\n",
    "    vol_audio = change_volume(audio, factor=1.5)\n",
    "    augmentations.append(('volume_up', vol_audio))\n",
    "\n",
    "    # Volume Change (increase volume)\n",
    "    vol_audio = change_volume(audio, factor=0.5)\n",
    "    augmentations.append(('volume_down', vol_audio))\n",
    "    \n",
    "    return augmentations\n",
    "\n",
    "def create_augmented_dataframe(df):\n",
    "    \"\"\"\n",
    "    Given a DataFrame of loaded audios, applies augmentations to each sample and\n",
    "    creates a new DataFrame that includes augmented versions.\n",
    "    \n",
    "    An additional column 'aug_method' indicates the augmentation applied.\n",
    "    \"\"\"\n",
    "    augmented_data = []\n",
    "    for idx, row in df.iterrows():\n",
    "        audio = row['audio']\n",
    "        sr = row['sample_rate']\n",
    "        label = row['label']\n",
    "        base_filepath = row['filepath']\n",
    "        filename = row['filename']\n",
    "        \n",
    "        aug_list = augment_audio(audio, sr)\n",
    "        for aug_method, aug_audio in aug_list:\n",
    "            try:\n",
    "                duration = librosa.get_duration(y=aug_audio, sr=sr)\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating duration for {filename} ({aug_method}): {e}\")\n",
    "                duration = None\n",
    "            \n",
    "            augmented_data.append({\n",
    "                'original_filepath': base_filepath,\n",
    "                'filename': filename,\n",
    "                'label': label,\n",
    "                'aug_method': aug_method,\n",
    "                'audio': aug_audio,\n",
    "                'sample_rate': sr,\n",
    "                'duration': duration\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(augmented_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba8bcfac-6035-4b21-824f-7466453d6d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_audio(audio, sr):\n",
    "    \"\"\"\n",
    "    Extracts a set of audio features from an already-loaded audio array.\n",
    "    \n",
    "    Features include:\n",
    "      - duration, zero crossing rate, spectral centroid, spectral rolloff,\n",
    "      - 13 MFCCs (mean values), RMS energy, and tempo.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    features['duration'] = librosa.get_duration(y=audio, sr=sr)\n",
    "    \n",
    "    # Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(audio)\n",
    "    features['zero_crossing_rate'] = float(np.mean(zcr))\n",
    "    \n",
    "    # Spectral Centroid\n",
    "    spec_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "    features['spectral_centroid'] = float(np.mean(spec_centroid))\n",
    "    \n",
    "    # Spectral Rolloff\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
    "    features['spectral_rolloff'] = float(np.mean(spec_rolloff))\n",
    "    \n",
    "    # MFCCs (first 13 coefficients)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    for i in range(13):\n",
    "        features[f'mfcc_{i+1}'] = float(np.mean(mfccs[i]))\n",
    "    \n",
    "    # RMS Energy\n",
    "    rms = librosa.feature.rms(y=audio)\n",
    "    features['rms'] = float(np.mean(rms))\n",
    "    \n",
    "    # Tempo (BPM)\n",
    "    try:\n",
    "        tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)\n",
    "        if isinstance(tempo, (list, np.ndarray)):\n",
    "            features['tempo'] = float(tempo[0])\n",
    "        elif isinstance(tempo, str):\n",
    "            features['tempo'] = float(tempo.strip(\"[]\"))\n",
    "        else:\n",
    "            features['tempo'] = float(tempo)\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing tempo: {e}\")\n",
    "        features['tempo'] = None\n",
    "\n",
    "    return features\n",
    "\n",
    "def create_features_from_augmented_dataframe(df_augmented):\n",
    "    \"\"\"\n",
    "    Given a DataFrame of augmented audios, extract audio features for each record.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Contains metadata along with the extracted features.\n",
    "    \"\"\"\n",
    "    feature_data = []\n",
    "    for idx, row in df_augmented.iterrows():\n",
    "        audio = row['audio']\n",
    "        sr = row['sample_rate']\n",
    "        features = extract_features_from_audio(audio, sr)\n",
    "        \n",
    "        record = {\n",
    "            'original_filepath': row['original_filepath'],\n",
    "            'filename': row['filename'],\n",
    "            'label': row['label'],\n",
    "            'aug_method': row['aug_method']\n",
    "        }\n",
    "        record.update(features)\n",
    "        feature_data.append(record)\n",
    "    \n",
    "    return pd.DataFrame(feature_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed01533-4732-41f2-bfc7-8327b2c6628e",
   "metadata": {},
   "source": [
    "Extraccion de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e82fdd40-b0b5-4bb7-8cdf-f8b66258cb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    \"\"\"\n",
    "    Loads an audio file and extracts several audio features,\n",
    "    ensuring that numerical features (like tempo) are stored as floats.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    features = {}\n",
    "    features['duration'] = librosa.get_duration(y=audio, sr=sr)\n",
    "    features['sample_rate'] = sr\n",
    "\n",
    "    # Zero Crossing Rate\n",
    "    zcr = librosa.feature.zero_crossing_rate(audio)\n",
    "    features['zero_crossing_rate'] = float(np.mean(zcr))\n",
    "\n",
    "    # Spectral Centroid\n",
    "    spec_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)\n",
    "    features['spectral_centroid'] = float(np.mean(spec_centroid))\n",
    "\n",
    "    # Spectral Rolloff\n",
    "    spec_rolloff = librosa.feature.spectral_rolloff(y=audio, sr=sr)\n",
    "    features['spectral_rolloff'] = float(np.mean(spec_rolloff))\n",
    "\n",
    "    # MFCCs (first 13 coefficients)\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "    for i in range(13):\n",
    "        features[f'mfcc_{i+1}'] = float(np.mean(mfccs[i]))\n",
    "\n",
    "    # RMS Energy\n",
    "    rms = librosa.feature.rms(y=audio)\n",
    "    features['rms'] = float(np.mean(rms))\n",
    "\n",
    "    # Tempo (BPM)\n",
    "    try:\n",
    "        tempo, _ = librosa.beat.beat_track(y=audio, sr=sr)\n",
    "        # Check if tempo is not a plain number\n",
    "        if isinstance(tempo, (list, np.ndarray)):\n",
    "            features['tempo'] = float(tempo[0])\n",
    "        elif isinstance(tempo, str):\n",
    "            # Remove any brackets and convert to float\n",
    "            features['tempo'] = float(tempo.strip(\"[]\"))\n",
    "        else:\n",
    "            features['tempo'] = float(tempo)\n",
    "    except Exception as e:\n",
    "        print(f\"Error computing tempo for {file_path}: {e}\")\n",
    "        features['tempo'] = None\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0eadba8f-f3c3-4079-af08-ba65e4ca9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_audio_files(root_folder, valid_extensions=('.wav', '.mp3', '.m4a', '.flac', '.ogg', '.wma', '.aac')):\n",
    "    \"\"\"\n",
    "    Recursively finds all audio files in the specified folder.\n",
    "    \n",
    "    Parameters:\n",
    "        root_folder (str): The folder in which to search.\n",
    "        valid_extensions (tuple): Allowed audio file extensions.\n",
    "    \n",
    "    Returns:\n",
    "        list: Full file paths of found audio files.\n",
    "    \"\"\"\n",
    "    audio_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_folder):\n",
    "        for filename in filenames:\n",
    "            if filename.lower().endswith(valid_extensions):\n",
    "                full_path = os.path.join(dirpath, filename)\n",
    "                audio_files.append(full_path)\n",
    "    return audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16ee2b3c-4b52-445b-9732-5e9bb2f71976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features_dataframe(root_folder=\"Audios\"):\n",
    "    \"\"\"\n",
    "    Extracts audio features for all files under the given folder and returns a DataFrame.\n",
    "    \n",
    "    Each row includes the file metadata and the extracted features.\n",
    "    \n",
    "    Parameters:\n",
    "        root_folder (str): Base folder containing audio files.\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with audio features.\n",
    "    \"\"\"\n",
    "    audio_files = find_audio_files(root_folder)\n",
    "    data = []\n",
    "    \n",
    "    for file_path in audio_files:\n",
    "        #print(f\"Extracting features from: {file_path}\")\n",
    "        features = extract_features(file_path)\n",
    "        if features is not None:\n",
    "            label = os.path.basename(os.path.dirname(file_path))\n",
    "            record = {\n",
    "                \"filepath\": file_path,\n",
    "                \"filename\": os.path.basename(file_path),\n",
    "                \"label\": label\n",
    "            }\n",
    "            record.update(features)\n",
    "            data.append(record)\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1db334f-2b90-4775-bf0f-fd5a93fd5fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generating Null Audio Files ===\n",
      "Generated: Audios/Audios_Null/null-01_01.wav\n",
      "Generated: Audios/Audios_Null/null-01_02.wav\n",
      "Generated: Audios/Audios_Null/null-01_03.wav\n",
      "Generated: Audios/Audios_Null/null-01_04.wav\n",
      "Generated: Audios/Audios_Null/null-01_05.wav\n",
      "Generated: Audios/Audios_Null/null-02_01.wav\n",
      "Generated: Audios/Audios_Null/null-02_02.wav\n",
      "Generated: Audios/Audios_Null/null-02_03.wav\n",
      "Generated: Audios/Audios_Null/null-02_04.wav\n",
      "Generated: Audios/Audios_Null/null-02_05.wav\n",
      "Generated: Audios/Audios_Null/null-03_01.wav\n",
      "Generated: Audios/Audios_Null/null-03_02.wav\n",
      "Generated: Audios/Audios_Null/null-03_03.wav\n",
      "Generated: Audios/Audios_Null/null-03_04.wav\n",
      "Generated: Audios/Audios_Null/null-03_05.wav\n",
      "\n",
      "=== Loading Audio Files ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x1/xs2knmd10t5759tsv29bkcv00000gn/T/ipykernel_9312/1355940325.py:25: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_data, sample_rate = librosa.load(filepath, sr=None)\n",
      "/Users/jorgemagdaleno/PycharmProjects/pythonProject/.venv/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Audios DataFrame:\n",
      "                      filepath         filename label  \\\n",
      "0  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis   \n",
      "1  Audios/Luis/LuisG-03_03.m4a  LuisG-03_03.m4a  Luis   \n",
      "2  Audios/Luis/LuisG-01_04.m4a  LuisG-01_04.m4a  Luis   \n",
      "3  Audios/Luis/LuisG-03_01.m4a  LuisG-03_01.m4a  Luis   \n",
      "4  Audios/Luis/LuisG-01_05.m4a  LuisG-01_05.m4a  Luis   \n",
      "\n",
      "                                               audio  sample_rate  duration  \n",
      "0  [-0.00064086914, -0.00036621094, -0.0005493164...        48000  2.281333  \n",
      "1  [-0.0016479492, -0.0016784668, -0.0018615723, ...        48000  2.644000  \n",
      "2  [0.0005187988, 0.00045776367, 0.00033569336, 0...        48000  4.073333  \n",
      "3  [-0.00033569336, -0.00024414062, -0.0004272461...        48000  2.324000  \n",
      "4  [-3.0517578e-05, -0.00064086914, -0.0006713867...        48000  3.156000  \n",
      "\n",
      "=== Creating Augmented Audio Versions ===\n",
      "Augmented Audios DataFrame:\n",
      "             original_filepath         filename label    aug_method  \\\n",
      "0  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis      original   \n",
      "1  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis         noise   \n",
      "2  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis  time_stretch   \n",
      "3  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis   pitch_shift   \n",
      "4  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis     volume_up   \n",
      "\n",
      "                                               audio  sample_rate  duration  \n",
      "0  [-0.00064086914, -0.00036621094, -0.0005493164...        48000  2.281333  \n",
      "1  [0.010799373138828177, -0.0005808364122216139,...        48000  2.281333  \n",
      "2  [-0.0006693449, -0.00040139956, -0.0005820912,...        48000  1.901104  \n",
      "3  [-0.00056019623, -0.00038439786, -0.0006150474...        48000  2.281333  \n",
      "4  [-0.0009613037, -0.0005493164, -0.0008239746, ...        48000  2.281333  \n",
      "\n",
      "=== Extracting Audio Features ===\n",
      "Extracted Audio Features DataFrame:\n",
      "             original_filepath         filename label    aug_method  duration  \\\n",
      "0  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis      original  2.281333   \n",
      "1  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis         noise  2.281333   \n",
      "2  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis  time_stretch  1.901104   \n",
      "3  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis   pitch_shift  2.281333   \n",
      "4  Audios/Luis/LuisG-03_02.m4a  LuisG-03_02.m4a  Luis     volume_up  2.281333   \n",
      "\n",
      "   zero_crossing_rate  spectral_centroid  spectral_rolloff      mfcc_1  \\\n",
      "0            0.050971        3128.588267       6806.512850 -470.027588   \n",
      "1            0.300414        9081.525544      17133.141063 -313.054723   \n",
      "2            0.053310        3125.840824       7052.199721 -498.277161   \n",
      "3            0.059819        3533.907520       7642.486857 -497.303436   \n",
      "4            0.050971        3128.588266       6806.512850 -430.182617   \n",
      "\n",
      "      mfcc_2  ...     mfcc_6    mfcc_7    mfcc_8    mfcc_9   mfcc_10  \\\n",
      "0  89.891869  ...  15.687697  4.556073  3.095508  1.611740  5.337509   \n",
      "1  33.389663  ...   9.520233  5.563023  1.048093  2.445112  2.973487   \n",
      "2  84.537102  ...  15.894697  4.773858  2.262989  1.278148  4.314846   \n",
      "3  84.401787  ...   9.657138  1.573075  0.197805  3.040892  0.265254   \n",
      "4  89.891884  ...  15.687698  4.556073  3.095509  1.611740  5.337510   \n",
      "\n",
      "    mfcc_11   mfcc_12   mfcc_13       rms       tempo  \n",
      "0 -5.140079  2.004782 -1.857108  0.034687  137.195122  \n",
      "1 -1.009193  0.606332  1.489601  0.036703  133.928571  \n",
      "2 -5.864370  1.201357 -1.775185  0.024946  165.441176  \n",
      "3 -4.452647  2.276324 -1.019287  0.023651  137.195122  \n",
      "4 -5.140080  2.004783 -1.857108  0.052030  137.195122  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "\n",
      "DataFrames have been saved to CSV files.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Generate Null (Silent) Audio Files\n",
    "print(\"=== Generating Null Audio Files ===\")\n",
    "generate_null_audios(n_files=3, duration=1.0)\n",
    "\n",
    "# Step 2: Load All Audio Files into a DataFrame\n",
    "print(\"\\n=== Loading Audio Files ===\")\n",
    "df_audios = load_audios_into_dataframe(\"Audios\")\n",
    "print(\"Loaded Audios DataFrame:\")\n",
    "print(df_audios.head())\n",
    "    \n",
    "# Step 3: Create Augmented Versions of Each Audio\n",
    "print(\"\\n=== Creating Augmented Audio Versions ===\")\n",
    "df_augmented = create_augmented_dataframe(df_audios)\n",
    "print(\"Augmented Audios DataFrame:\")\n",
    "print(df_augmented.head())\n",
    "    \n",
    "#Step 4: Extract Features from Each Audio File\n",
    "print(\"\\n=== Extracting Audio Features ===\")\n",
    "df_features = create_features_from_augmented_dataframe(df_augmented)\n",
    "print(\"Extracted Audio Features DataFrame:\")\n",
    "print(df_features.head())\n",
    "\n",
    "#Step 5: Save into CSV\n",
    "df_audios.to_csv(\"loaded_audios.csv\", index=False)\n",
    "df_augmented.to_csv(\"augmented_audios.csv\", index=False)\n",
    "df_features.to_csv(\"extracted_audio_features.csv\", index=False)\n",
    "print(\"\\nDataFrames have been saved to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29daf224-6ea8-4a92-83cc-7fb8f54b0fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LuisG 03 02\n"
     ]
    }
   ],
   "source": [
    "def parse_filename(filename):\n",
    "    # Remove file extension if present\n",
    "    base = os.path.splitext(filename)[0]\n",
    "    # Assume the format is Name-Phrase_ID\n",
    "    try:\n",
    "        name_phrase, recording_id = base.split('_')\n",
    "        name, phrase = name_phrase.split('-')\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Filename {filename} does not match expected format 'Name-Phrase_ID'\")\n",
    "    return name, phrase, recording_id\n",
    "\n",
    "# Example usage:\n",
    "filename = \"LuisG-03_02.wav\"\n",
    "speaker, phrase, rec_id = parse_filename(filename)\n",
    "print(speaker, phrase, rec_id)  # Output: LuisG 03 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d07e847-6879-4cda-a5cc-18d1e0daada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metadata_from_filename(df):\n",
    "    speakers, phrases = [], []\n",
    "    for fn in df['filename']:\n",
    "        speaker, phrase, _ = parse_filename(fn)\n",
    "        speakers.append(speaker)\n",
    "        phrases.append(phrase)\n",
    "    df['speaker'] = speakers\n",
    "    df['phrase'] = phrases\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b76d2b93-123e-427e-a52b-e53a39da6041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== In-Phrase Evaluation for Phrase 01 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AdriaM       1.00      1.00      1.00         4\n",
      "        AleM       1.00      1.00      1.00         3\n",
      "       BetoM       1.00      1.00      1.00         5\n",
      "       Bruce       1.00      1.00      1.00         4\n",
      "      Camila       1.00      1.00      1.00         5\n",
      "       Cielo       1.00      1.00      1.00         5\n",
      "      Daniel       0.92      1.00      0.96        12\n",
      "       David       1.00      1.00      1.00         6\n",
      "      Didier       0.86      1.00      0.92         6\n",
      "         Eri       1.00      1.00      1.00        12\n",
      "        Erik       1.00      1.00      1.00         9\n",
      "    Fernando       1.00      1.00      1.00         7\n",
      "        Irma       1.00      1.00      1.00         6\n",
      "       Jorge       1.00      1.00      1.00         6\n",
      "       LuisG       1.00      1.00      1.00         3\n",
      "       Maria       1.00      1.00      1.00         6\n",
      "     Mariana       1.00      1.00      1.00         5\n",
      "       Mario       1.00      1.00      1.00         8\n",
      "      Marlon       1.00      0.88      0.93         8\n",
      "        MauM       1.00      1.00      1.00         7\n",
      "      Sergio       1.00      0.67      0.80         3\n",
      "     Vanessa       1.00      1.00      1.00         4\n",
      "        null       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.99       144\n",
      "   macro avg       0.99      0.98      0.98       144\n",
      "weighted avg       0.99      0.99      0.99       144\n",
      "\n",
      "=== In-Phrase Evaluation for Phrase 02 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AdriaM       1.00      1.00      1.00         4\n",
      "        AleM       1.00      1.00      1.00         5\n",
      "       BetoM       1.00      1.00      1.00         6\n",
      "       Bruce       1.00      1.00      1.00        12\n",
      "      Camila       1.00      1.00      1.00         6\n",
      "       Cielo       1.00      1.00      1.00         6\n",
      "      Daniel       1.00      1.00      1.00         9\n",
      "       David       1.00      1.00      1.00         6\n",
      "      Didier       1.00      1.00      1.00         5\n",
      "         Eri       1.00      1.00      1.00         5\n",
      "        Erik       1.00      1.00      1.00         7\n",
      "    Fernando       1.00      1.00      1.00         5\n",
      "        Irma       1.00      1.00      1.00         7\n",
      "       Jorge       1.00      1.00      1.00         7\n",
      "       LuisG       1.00      0.88      0.93         8\n",
      "       Maria       1.00      1.00      1.00         5\n",
      "     Mariana       1.00      1.00      1.00         9\n",
      "       Mario       0.83      1.00      0.91         5\n",
      "      Marlon       1.00      1.00      1.00         3\n",
      "        MauM       1.00      1.00      1.00         7\n",
      "      Sergio       1.00      1.00      1.00         4\n",
      "     Vanessa       1.00      1.00      1.00         3\n",
      "        null       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.99       144\n",
      "   macro avg       0.99      0.99      0.99       144\n",
      "weighted avg       0.99      0.99      0.99       144\n",
      "\n",
      "=== In-Phrase Evaluation for Phrase 03 ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AdriaM       0.78      1.00      0.88         7\n",
      "        AleM       1.00      1.00      1.00         6\n",
      "       BetoM       1.00      1.00      1.00         2\n",
      "       Bruce       0.80      1.00      0.89         4\n",
      "      Camila       1.00      1.00      1.00         5\n",
      "       Cielo       1.00      0.80      0.89         5\n",
      "      Daniel       0.88      1.00      0.93        14\n",
      "       David       0.80      1.00      0.89         4\n",
      "      Didier       1.00      1.00      1.00         6\n",
      "         Eri       1.00      1.00      1.00        12\n",
      "        Erik       1.00      1.00      1.00         7\n",
      "    Fernando       0.83      0.83      0.83         6\n",
      "        Irma       1.00      1.00      1.00         6\n",
      "       Jorge       1.00      1.00      1.00         7\n",
      "       LuisG       1.00      1.00      1.00         3\n",
      "       Maria       1.00      1.00      1.00         6\n",
      "     Mariana       1.00      0.86      0.92         7\n",
      "       Mario       1.00      0.88      0.93         8\n",
      "      Marlon       1.00      0.62      0.77         8\n",
      "        MauM       1.00      0.75      0.86         4\n",
      "      Sergio       1.00      1.00      1.00         3\n",
      "     Vanessa       0.80      1.00      0.89         4\n",
      "        null       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.94       144\n",
      "   macro avg       0.95      0.95      0.94       144\n",
      "weighted avg       0.95      0.94      0.94       144\n",
      "\n",
      "\n",
      "=== Cross Testing Models on Other Phrases ===\n",
      "\n",
      "Model trained on phrase 01:\n",
      "\n",
      "  Testing on phrase 01:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AdriaM       1.00      1.00      1.00        30\n",
      "        AleM       1.00      1.00      1.00        30\n",
      "       BetoM       1.00      1.00      1.00        30\n",
      "       Bruce       1.00      1.00      1.00        30\n",
      "      Camila       1.00      1.00      1.00        30\n",
      "       Cielo       1.00      1.00      1.00        30\n",
      "      Daniel       0.98      1.00      0.99        60\n",
      "       David       1.00      1.00      1.00        30\n",
      "      Didier       0.97      1.00      0.98        30\n",
      "         Eri       1.00      1.00      1.00        30\n",
      "        Erik       1.00      1.00      1.00        30\n",
      "    Fernando       1.00      1.00      1.00        30\n",
      "        Irma       1.00      1.00      1.00        30\n",
      "       Jorge       1.00      1.00      1.00        30\n",
      "       LuisG       1.00      1.00      1.00        30\n",
      "       Maria       1.00      1.00      1.00        30\n",
      "     Mariana       1.00      1.00      1.00        30\n",
      "       Mario       1.00      1.00      1.00        30\n",
      "      Marlon       1.00      0.97      0.98        30\n",
      "        MauM       1.00      1.00      1.00        30\n",
      "      Sergio       1.00      0.97      0.98        30\n",
      "     Vanessa       1.00      1.00      1.00        30\n",
      "        null       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00       720\n",
      "   macro avg       1.00      1.00      1.00       720\n",
      "weighted avg       1.00      1.00      1.00       720\n",
      "\n",
      "\n",
      "  Testing on phrase 02:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AdriaM       0.85      0.37      0.51        30\n",
      "        AleM       0.62      0.97      0.75        30\n",
      "       BetoM       1.00      0.90      0.95        30\n",
      "       Bruce       1.00      0.97      0.98        30\n",
      "      Camila       0.91      1.00      0.95        30\n",
      "       Cielo       0.45      0.97      0.61        30\n",
      "      Daniel       0.81      0.97      0.88        60\n",
      "       David       0.79      1.00      0.88        30\n",
      "      Didier       0.72      0.87      0.79        30\n",
      "         Eri       1.00      0.33      0.50        30\n",
      "        Erik       0.93      0.43      0.59        30\n",
      "    Fernando       0.79      0.87      0.83        30\n",
      "        Irma       0.72      0.77      0.74        30\n",
      "       Jorge       1.00      0.67      0.80        30\n",
      "       LuisG       1.00      0.90      0.95        30\n",
      "       Maria       1.00      0.63      0.78        30\n",
      "     Mariana       0.64      0.53      0.58        30\n",
      "       Mario       0.91      1.00      0.95        30\n",
      "      Marlon       0.66      0.63      0.64        30\n",
      "        MauM       1.00      1.00      1.00        30\n",
      "      Sergio       0.84      0.53      0.65        30\n",
      "     Vanessa       0.41      0.53      0.46        30\n",
      "        null       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.78       720\n",
      "   macro avg       0.83      0.78      0.77       720\n",
      "weighted avg       0.83      0.78      0.78       720\n",
      "\n",
      "\n",
      "  Testing on phrase 03:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AdriaM       0.24      0.17      0.20        30\n",
      "        AleM       0.49      0.83      0.62        30\n",
      "       BetoM       0.64      0.70      0.67        30\n",
      "       Bruce       0.59      0.43      0.50        30\n",
      "      Camila       0.45      0.83      0.59        30\n",
      "       Cielo       0.67      0.87      0.75        30\n",
      "      Daniel       0.48      0.93      0.64        60\n",
      "       David       1.00      0.40      0.57        30\n",
      "      Didier       1.00      0.33      0.50        30\n",
      "         Eri       0.14      0.03      0.05        30\n",
      "        Erik       0.07      0.07      0.07        30\n",
      "    Fernando       0.81      0.97      0.88        30\n",
      "        Irma       0.73      0.73      0.73        30\n",
      "       Jorge       0.63      0.57      0.60        30\n",
      "       LuisG       0.50      0.70      0.58        30\n",
      "       Maria       0.00      0.00      0.00        30\n",
      "     Mariana       0.31      0.37      0.34        30\n",
      "       Mario       0.50      0.43      0.46        30\n",
      "      Marlon       0.20      0.10      0.13        30\n",
      "        MauM       0.00      0.00      0.00        30\n",
      "      Sergio       0.88      0.47      0.61        30\n",
      "     Vanessa       0.22      0.27      0.24        30\n",
      "        null       0.71      1.00      0.83        30\n",
      "\n",
      "    accuracy                           0.51       720\n",
      "   macro avg       0.49      0.49      0.46       720\n",
      "weighted avg       0.49      0.51      0.47       720\n",
      "\n",
      "\n",
      "Model trained on phrase 02:\n",
      "\n",
      "  Testing on phrase 01:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AdriaM       0.43      0.10      0.16        30\n",
      "        AleM       1.00      0.97      0.98        30\n",
      "       BetoM       0.59      0.97      0.73        30\n",
      "       Bruce       0.83      0.80      0.81        30\n",
      "      Camila       0.71      0.97      0.82        30\n",
      "       Cielo       0.88      0.73      0.80        30\n",
      "      Daniel       0.72      0.93      0.81        60\n",
      "       David       0.68      1.00      0.81        30\n",
      "      Didier       0.68      0.57      0.62        30\n",
      "         Eri       1.00      0.13      0.24        30\n",
      "        Erik       0.42      0.57      0.49        30\n",
      "    Fernando       0.85      0.93      0.89        30\n",
      "        Irma       0.90      0.93      0.92        30\n",
      "       Jorge       1.00      0.57      0.72        30\n",
      "       LuisG       0.97      1.00      0.98        30\n",
      "       Maria       0.70      1.00      0.82        30\n",
      "     Mariana       1.00      0.07      0.12        30\n",
      "       Mario       0.77      1.00      0.87        30\n",
      "      Marlon       0.75      0.30      0.43        30\n",
      "        MauM       0.68      1.00      0.81        30\n",
      "      Sergio       0.65      0.93      0.77        30\n",
      "     Vanessa       1.00      0.77      0.87        30\n",
      "        null       0.97      1.00      0.98        30\n",
      "\n",
      "    accuracy                           0.76       720\n",
      "   macro avg       0.79      0.75      0.72       720\n",
      "weighted avg       0.79      0.76      0.72       720\n",
      "\n",
      "\n",
      "  Testing on phrase 02:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AdriaM       1.00      1.00      1.00        30\n",
      "        AleM       1.00      1.00      1.00        30\n",
      "       BetoM       1.00      1.00      1.00        30\n",
      "       Bruce       1.00      1.00      1.00        30\n",
      "      Camila       1.00      1.00      1.00        30\n",
      "       Cielo       1.00      1.00      1.00        30\n",
      "      Daniel       1.00      1.00      1.00        60\n",
      "       David       1.00      1.00      1.00        30\n",
      "      Didier       1.00      1.00      1.00        30\n",
      "         Eri       1.00      1.00      1.00        30\n",
      "        Erik       1.00      1.00      1.00        30\n",
      "    Fernando       1.00      1.00      1.00        30\n",
      "        Irma       1.00      1.00      1.00        30\n",
      "       Jorge       1.00      1.00      1.00        30\n",
      "       LuisG       1.00      0.97      0.98        30\n",
      "       Maria       1.00      1.00      1.00        30\n",
      "     Mariana       1.00      1.00      1.00        30\n",
      "       Mario       0.97      1.00      0.98        30\n",
      "      Marlon       1.00      1.00      1.00        30\n",
      "        MauM       1.00      1.00      1.00        30\n",
      "      Sergio       1.00      1.00      1.00        30\n",
      "     Vanessa       1.00      1.00      1.00        30\n",
      "        null       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           1.00       720\n",
      "   macro avg       1.00      1.00      1.00       720\n",
      "weighted avg       1.00      1.00      1.00       720\n",
      "\n",
      "\n",
      "  Testing on phrase 03:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AdriaM       0.00      0.00      0.00        30\n",
      "        AleM       0.79      0.90      0.84        30\n",
      "       BetoM       0.60      0.97      0.74        30\n",
      "       Bruce       0.77      1.00      0.87        30\n",
      "      Camila       0.46      0.80      0.59        30\n",
      "       Cielo       0.48      0.33      0.39        30\n",
      "      Daniel       0.61      0.82      0.70        60\n",
      "       David       0.77      0.33      0.47        30\n",
      "      Didier       0.31      0.30      0.31        30\n",
      "         Eri       0.38      0.17      0.23        30\n",
      "        Erik       0.40      0.70      0.51        30\n",
      "    Fernando       0.77      0.90      0.83        30\n",
      "        Irma       1.00      0.20      0.33        30\n",
      "       Jorge       0.83      0.17      0.28        30\n",
      "       LuisG       0.92      0.73      0.81        30\n",
      "       Maria       0.00      0.00      0.00        30\n",
      "     Mariana       0.00      0.00      0.00        30\n",
      "       Mario       0.81      0.83      0.82        30\n",
      "      Marlon       0.43      0.53      0.48        30\n",
      "        MauM       0.50      0.33      0.40        30\n",
      "      Sergio       0.44      0.67      0.53        30\n",
      "     Vanessa       0.42      0.60      0.49        30\n",
      "        null       0.70      1.00      0.82        30\n",
      "\n",
      "    accuracy                           0.55       720\n",
      "   macro avg       0.54      0.53      0.50       720\n",
      "weighted avg       0.54      0.55      0.51       720\n",
      "\n",
      "\n",
      "Model trained on phrase 03:\n",
      "\n",
      "  Testing on phrase 01:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AdriaM       0.00      0.00      0.00        30\n",
      "        AleM       1.00      0.67      0.80        30\n",
      "       BetoM       0.52      1.00      0.68        30\n",
      "       Bruce       0.67      0.20      0.31        30\n",
      "      Camila       0.66      0.90      0.76        30\n",
      "       Cielo       1.00      0.90      0.95        30\n",
      "      Daniel       0.64      0.82      0.72        60\n",
      "       David       0.66      0.83      0.74        30\n",
      "      Didier       0.33      0.47      0.38        30\n",
      "         Eri       0.80      0.13      0.23        30\n",
      "        Erik       1.00      0.33      0.50        30\n",
      "    Fernando       0.72      0.77      0.74        30\n",
      "        Irma       0.94      0.97      0.95        30\n",
      "       Jorge       1.00      0.13      0.24        30\n",
      "       LuisG       0.43      0.87      0.58        30\n",
      "       Maria       0.00      0.00      0.00        30\n",
      "     Mariana       0.80      0.93      0.86        30\n",
      "       Mario       0.61      1.00      0.76        30\n",
      "      Marlon       0.58      0.70      0.64        30\n",
      "        MauM       0.19      0.20      0.20        30\n",
      "      Sergio       0.47      0.80      0.59        30\n",
      "     Vanessa       0.00      0.00      0.00        30\n",
      "        null       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.60       720\n",
      "   macro avg       0.61      0.59      0.55       720\n",
      "weighted avg       0.61      0.60      0.56       720\n",
      "\n",
      "\n",
      "  Testing on phrase 02:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AdriaM       0.00      0.00      0.00        30\n",
      "        AleM       1.00      0.60      0.75        30\n",
      "       BetoM       0.77      1.00      0.87        30\n",
      "       Bruce       1.00      0.63      0.78        30\n",
      "      Camila       0.75      0.90      0.82        30\n",
      "       Cielo       0.34      0.80      0.48        30\n",
      "      Daniel       0.74      0.92      0.82        60\n",
      "       David       0.85      0.57      0.68        30\n",
      "      Didier       0.15      0.20      0.17        30\n",
      "         Eri       0.83      0.17      0.28        30\n",
      "        Erik       1.00      0.67      0.80        30\n",
      "    Fernando       0.83      0.67      0.74        30\n",
      "        Irma       0.47      0.93      0.63        30\n",
      "       Jorge       1.00      0.07      0.12        30\n",
      "       LuisG       0.57      0.53      0.55        30\n",
      "       Maria       0.00      0.00      0.00        30\n",
      "     Mariana       0.00      0.00      0.00        30\n",
      "       Mario       0.94      1.00      0.97        30\n",
      "      Marlon       0.56      0.83      0.67        30\n",
      "        MauM       0.07      0.13      0.10        30\n",
      "      Sergio       0.50      0.77      0.61        30\n",
      "     Vanessa       0.82      0.47      0.60        30\n",
      "        null       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.57       720\n",
      "   macro avg       0.62      0.56      0.54       720\n",
      "weighted avg       0.62      0.57      0.55       720\n",
      "\n",
      "\n",
      "  Testing on phrase 03:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      AdriaM       0.94      1.00      0.97        30\n",
      "        AleM       1.00      1.00      1.00        30\n",
      "       BetoM       1.00      1.00      1.00        30\n",
      "       Bruce       0.97      1.00      0.98        30\n",
      "      Camila       1.00      1.00      1.00        30\n",
      "       Cielo       1.00      0.97      0.98        30\n",
      "      Daniel       0.97      1.00      0.98        60\n",
      "       David       0.97      1.00      0.98        30\n",
      "      Didier       1.00      1.00      1.00        30\n",
      "         Eri       1.00      1.00      1.00        30\n",
      "        Erik       1.00      1.00      1.00        30\n",
      "    Fernando       0.97      0.97      0.97        30\n",
      "        Irma       1.00      1.00      1.00        30\n",
      "       Jorge       1.00      1.00      1.00        30\n",
      "       LuisG       1.00      1.00      1.00        30\n",
      "       Maria       1.00      1.00      1.00        30\n",
      "     Mariana       1.00      0.97      0.98        30\n",
      "       Mario       1.00      0.97      0.98        30\n",
      "      Marlon       1.00      0.90      0.95        30\n",
      "        MauM       1.00      0.97      0.98        30\n",
      "      Sergio       1.00      1.00      1.00        30\n",
      "     Vanessa       0.97      1.00      0.98        30\n",
      "        null       1.00      1.00      1.00        30\n",
      "\n",
      "    accuracy                           0.99       720\n",
      "   macro avg       0.99      0.99      0.99       720\n",
      "weighted avg       0.99      0.99      0.99       720\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorgemagdaleno/PycharmProjects/pythonProject/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgemagdaleno/PycharmProjects/pythonProject/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/jorgemagdaleno/PycharmProjects/pythonProject/.venv/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.read_csv(\"extracted_audio_features.csv\")\n",
    "\n",
    "# Extract speaker and phrase from the filename and add them as columns\n",
    "speakers, phrases = [], []\n",
    "for fn in df_features['filename']:\n",
    "    speaker, phrase, _ = parse_filename(fn)\n",
    "    speakers.append(speaker)\n",
    "    phrases.append(phrase)\n",
    "df_features['speaker'] = speakers\n",
    "df_features['phrase'] = phrases\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 1: Define the Feature Columns\n",
    "# -----------------------------------------------------------------------------\n",
    "# Adjust this list as needed to match the features you have extracted.\n",
    "feature_columns = ['zero_crossing_rate', 'spectral_centroid',\n",
    "                   'spectral_rolloff', 'rms', 'tempo'] + [f'mfcc_{i+1}' for i in range(13)]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 2: Train One Model per Phrase and Store Data for Cross Testing\n",
    "# -----------------------------------------------------------------------------\n",
    "phrase_models = {}  # Will hold the trained model for each phrase\n",
    "phrase_data = {}    # Will hold the X, y data for each phrase (all samples, not split)\n",
    "\n",
    "for phrase in [\"01\", \"02\", \"03\"]:\n",
    "    # Filter the DataFrame for the current phrase\n",
    "    df_phrase = df_features[df_features['phrase'] == phrase]\n",
    "    X = df_phrase[feature_columns]\n",
    "    y = df_phrase['speaker']\n",
    "    \n",
    "    # Save the data for cross testing later\n",
    "    phrase_data[phrase] = (X, y)\n",
    "    \n",
    "    # For the in-phrase evaluation, split into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train a RandomForest classifier (you can choose another classifier if desired)\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # In-phrase evaluation (model trained on phrase, tested on the same phrase)\n",
    "    print(f\"=== In-Phrase Evaluation for Phrase {phrase} ===\")\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Save the trained model\n",
    "    phrase_models[phrase] = clf\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Step 3: Cross Testing: Evaluate Each Model on Data from All Phrases\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"\\n=== Cross Testing Models on Other Phrases ===\")\n",
    "for train_phrase, model in phrase_models.items():\n",
    "    print(f\"\\nModel trained on phrase {train_phrase}:\")\n",
    "    for test_phrase, (X_test, y_test) in phrase_data.items():\n",
    "        y_pred = model.predict(X_test)\n",
    "        print(f\"\\n  Testing on phrase {test_phrase}:\")\n",
    "        print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cab8420-cabc-4fb6-82ab-9f06914b3d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for phrase 01 exported to model_phrase_01.pkl\n",
      "Model for phrase 02 exported to model_phrase_02.pkl\n",
      "Model for phrase 03 exported to model_phrase_03.pkl\n"
     ]
    }
   ],
   "source": [
    "# After training each model, export it:\n",
    "for phrase, model in phrase_models.items():\n",
    "    filename = f\"model_phrase_{phrase}.pkl\"\n",
    "    joblib.dump(model, filename)\n",
    "    print(f\"Model for phrase {phrase} exported to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e58724d4-41a0-4356-b9b2-fdfe1cec75a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting real-time inference. Speak into your microphone...\n",
      "Predicted Speaker 1: Jorge\n",
      "Predicted Speaker 2: Jorge\n",
      "Predicted Speaker 3: Jorge\n",
      "Predicted Speaker 1: null\n",
      "Predicted Speaker 2: null\n",
      "Predicted Speaker 3: null\n",
      "Predicted Speaker 1: Jorge\n",
      "Predicted Speaker 2: Jorge\n",
      "Predicted Speaker 3: Jorge\n",
      "Predicted Speaker 1: Jorge\n",
      "Predicted Speaker 2: Jorge\n",
      "Predicted Speaker 3: Jorge\n",
      "Predicted Speaker 1: Jorge\n",
      "Predicted Speaker 2: Jorge\n",
      "Predicted Speaker 3: Jorge\n",
      "Predicted Speaker 1: Jorge\n",
      "Predicted Speaker 2: Jorge\n",
      "Predicted Speaker 3: Jorge\n",
      "Predicted Speaker 1: Didier\n",
      "Predicted Speaker 2: Didier\n",
      "Predicted Speaker 3: Didier\n",
      "Predicted Speaker 1: Erik\n",
      "Predicted Speaker 2: Erik\n",
      "Predicted Speaker 3: Erik\n",
      "Predicted Speaker 1: Didier\n",
      "Predicted Speaker 2: Didier\n",
      "Predicted Speaker 3: Didier\n",
      "Real-time inference stopped.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import sounddevice as sd\n",
    "import joblib\n",
    "\n",
    "# -------------------------------\n",
    "# Minimal Recording Function\n",
    "# -------------------------------\n",
    "def record_audio(duration=4, sample_rate=44100):\n",
    "    \"\"\"\n",
    "    Records audio from the microphone for a given duration.\n",
    "    \n",
    "    Returns:\n",
    "        audio (np.ndarray): Recorded 1D audio array.\n",
    "        sample_rate (int): The sampling rate.\n",
    "    \"\"\"\n",
    "    #print(f\"Recording for {duration} seconds...\")\n",
    "    audio = sd.rec(int(duration * sample_rate), samplerate=sample_rate, channels=1)\n",
    "    sd.wait()  # Wait until recording finishes\n",
    "    return np.squeeze(audio), sample_rate\n",
    "\n",
    "# -------------------------------\n",
    "# Minimal Model Loading and Prediction Functions\n",
    "# -------------------------------\n",
    "def load_model(model_filename):\n",
    "    \"\"\"\n",
    "    Loads a pre-trained model from disk.\n",
    "    \"\"\"\n",
    "    return joblib.load(model_filename)\n",
    "\n",
    "def predict_speaker(model, feature_vector):\n",
    "    \"\"\"\n",
    "    Predicts the speaker from the feature vector using the loaded model.\n",
    "    \n",
    "    Args:\n",
    "        model: Pre-trained classifier.\n",
    "        feature_vector (np.ndarray): 1D array of features.\n",
    "        \n",
    "    Returns:\n",
    "        The predicted speaker (string).\n",
    "    \"\"\"\n",
    "    # The model expects a 2D array: (1, number_of_features)\n",
    "    prediction = model.predict(feature_vector)\n",
    "    return prediction[0]\n",
    "\n",
    "# -------------------------------\n",
    "# Main Real-Time Inference Loop\n",
    "# -------------------------------\n",
    "def main_inference_loop():\n",
    "    # Load your pre-trained model (assumed to be saved already)\n",
    "    model_1 = load_model(\"model_phrase_01.pkl\")\n",
    "    model_2 = load_model(\"model_phrase_02.pkl\")\n",
    "    model_3 = load_model(\"model_phrase_03.pkl\")\n",
    "    \n",
    "    # FEATURE_COLUMNS is assumed to be defined in your notebook\n",
    "    # For example:\n",
    "    # FEATURE_COLUMNS = ['duration', 'zero_crossing_rate', 'spectral_centroid', 'spectral_rolloff',\n",
    "    #                    'rms', 'tempo'] + [f'mfcc_{i+1}' for i in range(13)]\n",
    "    \n",
    "    print(\"Starting real-time inference. Speak into your microphone...\")\n",
    "    try:\n",
    "        while True:\n",
    "            # 1. Record audio from the mic.\n",
    "            audio, sr = record_audio()\n",
    "            \n",
    "            # 2. Extract features using your already-defined function.\n",
    "            # This function should return a dictionary mapping feature names to values.\n",
    "            features = extract_features_from_audio(audio, sr)\n",
    "            \n",
    "            # 3. Create a feature vector in the same order as used during training.\n",
    "            feature_vector = pd.DataFrame([features], columns=feature_columns)\n",
    "            #print(feature_vector.head())\n",
    "            # 4. Get the prediction from the model.\n",
    "            predicted_speaker_1 = predict_speaker(model_1, feature_vector)\n",
    "            predicted_speaker_2 = predict_speaker(model_2, feature_vector)\n",
    "            predicted_speaker_3 = predict_speaker(model_3, feature_vector)\n",
    "            print(\"Predicted Speaker 1:\", predicted_speaker_1)\n",
    "            print(\"Predicted Speaker 2:\", predicted_speaker_1)\n",
    "            print(\"Predicted Speaker 3:\", predicted_speaker_1)\n",
    "            # Optional: pause briefly before the next recording.\n",
    "            time.sleep(0.5)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Real-time inference stopped.\")\n",
    "\n",
    "# Run the inference loop if executed as a script or in a notebook cell.\n",
    "if __name__ == \"__main__\":\n",
    "    main_inference_loop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "729f7ca6-b98f-447f-b636-5e029ad25934",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install sounddevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d90081f-9e74-4bd1-89e0-277a09efa7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Speaker1: ['Jorge']\n",
      "Predicted Speaker2: ['Jorge']\n",
      "Predicted Speaker3: ['Jorge']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x1/xs2knmd10t5759tsv29bkcv00000gn/T/ipykernel_9312/256191575.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(audio_path, sr=None)\n",
      "/Users/jorgemagdaleno/PycharmProjects/pythonProject/.venv/lib/python3.9/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    }
   ],
   "source": [
    "# Load your saved audio file (ensure the path is correct)\n",
    "audio_path = \"Testing_Audios/TestJ2.m4a\"\n",
    "audio, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "# Use your existing function to extract features from the audio.\n",
    "# This function should return a dictionary with keys matching FEATURE_COLUMNS.\n",
    "features = extract_features_from_audio(audio, sr)\n",
    "\n",
    "# Convert the feature dictionary to a DataFrame so the feature names are preserved.\n",
    "feature_vector = pd.DataFrame([features], columns=feature_columns)\n",
    "\n",
    "# Load your pre-trained model (assumed to be exported using joblib)\n",
    "model_1 = load_model(\"model_phrase_01.pkl\")\n",
    "model_2 = load_model(\"model_phrase_02.pkl\")\n",
    "model_3 = load_model(\"model_phrase_03.pkl\")\n",
    "\n",
    "# Predict the speaker using the model.\n",
    "predicted_speaker1 = model_1.predict(feature_vector)\n",
    "predicted_speaker2 = model_2.predict(feature_vector)\n",
    "predicted_speaker3 = model_3.predict(feature_vector)\n",
    "\n",
    "print(\"Predicted Speaker1:\", predicted_speaker1)\n",
    "print(\"Predicted Speaker2:\", predicted_speaker2)\n",
    "print(\"Predicted Speaker3:\", predicted_speaker3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb3754-5a4d-4a3b-a405-33e00139ea28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac9f70c-9d12-42c9-942a-65abf133e438",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
